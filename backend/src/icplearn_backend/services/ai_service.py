from kybra import query, update, ic, Opt, Principal
from typing import Dict, List, Any, Optional
import json
import time

# In-memory storage for AI prompts and responses (would use stable storage in production)
ai_prompts = {}
ai_responses = {}
ai_agent_cache = {}  # Cache for agent configurations

# Hybrid AI Service Configuration
class AIServiceConfig:
    MAX_RETRIES = 2
    TIMEOUT_SECONDS = 10
    FALLBACK_ENABLED = True
    ICP_LLM_CANISTER_ID = ""  # Would be set to actual LLM canister ID
    EXTERNAL_AI_ENABLED = True

# AI Service Status Tracking
ai_service_stats = {
    "icp_llm_calls": 0,
    "external_api_calls": 0,
    "fallback_calls": 0,
    "total_calls": 0,
    "success_rate": 0.0
}

# ============================================================================
# HYBRID AI SERVICE FUNCTIONS - ICP DeAI Implementation
# ============================================================================

def _try_icp_llm_canister(prompt: str, agent_type: str = "general") -> Optional[str]:
    """
    Try to use ICP's native LLM Canister for sovereign AI.
    This implements true DeAI by running AI directly on ICP.
    """
    try:
        # Check if ICP LLM Canister is available
        if not AIServiceConfig.ICP_LLM_CANISTER_ID:
            return None
            
        # TODO: Implement actual inter-canister call to LLM Canister
        # This would be the real implementation:
        # response = ic.call(AIServiceConfig.ICP_LLM_CANISTER_ID, "generate", {
        #     "prompt": prompt,
        #     "model": "llama-3.1-8b",
        #     "max_tokens": 150,
        #     "temperature": 0.7
        # })
        
        ai_service_stats["icp_llm_calls"] += 1
        ic.print(f"ICP LLM Canister called for: {agent_type}")
        
        # For now, return None to indicate not yet implemented
        return None
        
    except Exception as e:
        ic.print(f"ICP LLM Canister error: {e}")
        return None

def _try_external_ai_api(prompt: str, agent_type: str = "general") -> Optional[str]:
    """
    Try external AI API using ICP's HTTPS outcalls.
    This maintains some sovereignty while accessing external AI.
    """
    try:
        if not AIServiceConfig.EXTERNAL_AI_ENABLED:
            return None
            
        # TODO: Implement actual HTTPS outcall
        # This would be the real implementation using ic.http_request:
        # 
        # headers = {
        #     "Authorization": f"Bearer {api_key}",
        #     "Content-Type": "application/json"
        # }
        # 
        # payload = {
        #     "model": "gpt-4",
        #     "messages": [
        #         {"role": "system", "content": f"You are a {agent_type} AI assistant."},
        #         {"role": "user", "content": prompt}
        #     ],
        #     "max_tokens": 150,
        #     "temperature": 0.7
        # }
        # 
        # response = ic.http_request({
        #     "url": "https://api.openai.com/v1/chat/completions",
        #     "method": "POST",
        #     "headers": headers,
        #     "body": json.dumps(payload).encode(),
        #     "transform": None
        # })
        
        ai_service_stats["external_api_calls"] += 1
        ic.print(f"External AI API called for: {agent_type}")
        
        # For now, return None to indicate not yet implemented
        return None
        
    except Exception as e:
        ic.print(f"External AI API error: {e}")
        return None

def _generate_intelligent_fallback(prompt: str, agent_type: str = "general", context: Optional[str] = None) -> str:
    """
    Generate intelligent fallback responses based on prompt analysis.
    This ensures the system always works, even without external AI.
    Implements educational AI sovereignty.
    """
    ai_service_stats["fallback_calls"] += 1
    
    prompt_lower = prompt.lower()
    
    # Educational content generation
    if "generate course" in prompt_lower or "course content" in prompt_lower:
        return _generate_course_fallback(prompt)
    
    # Answer validation
    elif "validate" in prompt_lower and "answer" in prompt_lower:
        return _generate_validation_fallback(prompt)
    
    # NFT metadata generation
    elif "nft" in prompt_lower and "metadata" in prompt_lower:
        return _generate_nft_fallback(prompt)
    
    # Learning pattern analysis
    elif "analyze" in prompt_lower and "learning" in prompt_lower:
        return _generate_analysis_fallback(prompt)
    
    # Chat/tutoring responses
    elif agent_type == "tutor" or "explain" in prompt_lower or "help" in prompt_lower:
        return _generate_tutor_fallback(prompt, context)
    
    # General educational response
    else:
        return _generate_general_educational_fallback(prompt)

def _generate_course_fallback(prompt: str) -> str:
    """Generate course content fallback."""
    # Extract topic from prompt (simple parsing)
    topic = "the subject"
    if "about" in prompt:
        parts = prompt.split("about")
        if len(parts) > 1:
            topic = parts[1].split("at")[0].strip()
    
    return f"""# {topic.title()} Course

## ðŸŽ¯ Learning Objectives
By the end of this course, you will:
- Understand the core concepts of {topic}
- Apply {topic} principles in practical scenarios
- Build confidence in {topic} through hands-on practice

## ðŸ“š Course Structure

### Module 1: Foundations
- Introduction to {topic}
- Key terminology and concepts
- Historical context and importance

### Module 2: Core Principles
- Fundamental principles of {topic}
- How {topic} works in practice
- Common patterns and best practices

### Module 3: Practical Application
- Hands-on exercises and projects
- Real-world case studies
- Problem-solving techniques

### Module 4: Advanced Topics
- Advanced concepts in {topic}
- Integration with other technologies
- Future trends and developments

## ðŸŽ“ Assessment
- Interactive quizzes after each module
- Practical projects to demonstrate understanding
- Final capstone project

## ðŸ“– Additional Resources
- Recommended reading materials
- Online tutorials and videos
- Community forums and discussion groups

This course is designed to provide a comprehensive understanding of {topic} through interactive learning and practical application."""

def _generate_tutor_fallback(prompt: str, context: Optional[str] = None) -> str:
    """Generate tutoring response fallback."""
    prompt_lower = prompt.lower()
    
    # Blockchain/ICP specific responses
    if any(keyword in prompt_lower for keyword in ["blockchain", "icp", "canister", "smart contract"]):
        return """Great question about blockchain technology! Let me explain:

ðŸ”¹ **Blockchain** is a distributed ledger technology that maintains a continuously growing list of records
ðŸ”¹ **ICP (Internet Computer)** is a revolutionary blockchain that can host full web applications
ðŸ”¹ **Canisters** are ICP's smart contracts - they're more powerful than traditional smart contracts
ðŸ”¹ **Smart Contracts** are self-executing contracts with terms directly written into code

The key advantage of ICP is that canisters can:
- Store large amounts of data efficiently
- Serve web pages directly
- Make HTTP requests to external services
- Run complex computations

What specific aspect would you like me to explain further?"""
    
    # Programming help
    elif any(keyword in prompt_lower for keyword in ["code", "programming", "function", "debug"]):
        return """I'm here to help with your programming questions! ðŸ’»

**General Programming Tips:**
1. **Break down the problem** - Divide complex tasks into smaller steps
2. **Plan before coding** - Write pseudocode or outline your approach
3. **Test frequently** - Run your code often to catch errors early
4. **Read error messages** - They often tell you exactly what's wrong

**Debugging Strategy:**
- Use print statements to trace execution
- Check variable values at different points
- Test with simple inputs first
- Look for common issues (typos, syntax errors, logic errors)

**Best Practices:**
- Use meaningful variable names
- Write comments to explain complex logic
- Keep functions small and focused
- Follow consistent formatting

What specific programming challenge are you working on?"""
    
    # Learning and study help
    elif any(keyword in prompt_lower for keyword in ["learn", "study", "understand", "explain"]):
        return """I'm excited to help you learn! ðŸ“š

**Effective Learning Strategies:**

ðŸŽ¯ **Active Learning:**
- Don't just read - practice and apply concepts
- Teach concepts to others (or explain them out loud)
- Create your own examples and analogies

ðŸ“ **Study Techniques:**
- Take notes in your own words
- Create mind maps or diagrams
- Use spaced repetition for memorization
- Practice retrieval (test yourself without looking)

ðŸ”„ **Learning Process:**
1. **Understand** - Make sure you grasp the concept
2. **Practice** - Apply the knowledge in exercises
3. **Reflect** - Think about what you've learned
4. **Connect** - Relate new knowledge to what you already know

ðŸ’¡ **Tips for Success:**
- Set specific, achievable goals
- Take regular breaks (try the Pomodoro Technique)
- Find your optimal learning environment
- Don't be afraid to ask questions!

What topic are you trying to master?"""
    
    # Default encouraging response
    else:
        return """Hello! I'm here to help you on your learning journey! ðŸŒŸ

I can assist you with:
- **Blockchain & ICP Development** - Canisters, smart contracts, Web3 concepts
- **Programming** - Code help, debugging, best practices
- **Learning Strategies** - Study techniques, concept explanations
- **Project Guidance** - Planning, problem-solving, implementation

Feel free to ask me anything! Whether you need:
- Concept explanations
- Code review and debugging help
- Learning path recommendations
- Study strategies and tips

I'm designed to provide helpful, encouraging, and practical guidance. What would you like to explore today?"""

def _generate_general_educational_fallback(prompt: str) -> str:
    """Generate general educational response."""
    return """Thank you for your question! I'm here to provide educational support and guidance.

ðŸŽ“ **Learning Approach:**
- I'll help break down complex topics into understandable parts
- Provide practical examples and real-world applications
- Offer study strategies and learning tips
- Support your educational journey with encouragement

ðŸ“š **Areas I can help with:**
- Blockchain and Web3 technologies
- Programming and software development
- Learning strategies and study techniques
- Project planning and problem-solving

Please feel free to ask more specific questions, and I'll provide detailed, helpful responses tailored to your learning needs!"""

def _generate_validation_fallback(prompt: str) -> str:
    """Generate validation response fallback."""
    return """I'll help validate this answer with detailed feedback:

âœ… **Validation Process:**
1. **Accuracy Check** - Comparing key concepts and facts
2. **Completeness Review** - Ensuring all important points are covered
3. **Clarity Assessment** - Evaluating how well the answer explains the concept

ðŸ“ **Feedback Guidelines:**
- Positive reinforcement for correct elements
- Constructive suggestions for improvement
- Additional resources for deeper understanding
- Encouragement to keep learning

Based on the content provided, I'll provide specific feedback on accuracy, completeness, and areas for improvement."""

def _generate_nft_fallback(prompt: str) -> str:
    """Generate NFT metadata fallback."""
    return """{
  "name": "ICPlearn Skill Achievement",
  "description": "This NFT represents mastery of a specific skill on the ICPlearn platform.",
  "image": "https://icplearn.io/nft/achievement.png",
  "attributes": [
    {"trait_type": "Platform", "value": "ICPlearn"},
    {"trait_type": "Type", "value": "Skill Achievement"},
    {"trait_type": "Blockchain", "value": "Internet Computer"}
  ]
}"""

def _generate_analysis_fallback(prompt: str) -> str:
    """Generate learning analysis fallback."""
    return """ðŸ“Š **Learning Pattern Analysis**

ðŸŽ¯ **Strengths Identified:**
- Consistent engagement with learning materials
- Good retention of core concepts
- Active participation in practical exercises

ðŸ“ˆ **Areas for Growth:**
- Could benefit from more hands-on practice
- Consider reviewing foundational concepts periodically
- Explore advanced topics to challenge understanding

ðŸ’¡ **Personalized Recommendations:**
- Set aside 30-45 minutes daily for focused study
- Use active recall techniques (testing yourself)
- Join study groups or discussion forums
- Apply concepts through personal projects

ðŸ”„ **Learning Style Optimization:**
- Mix theoretical study with practical application
- Use visual aids and diagrams when possible
- Break complex topics into smaller, manageable chunks
- Regular review sessions to reinforce learning

This analysis is based on general learning principles and can be refined with more specific user data."""

def _parse_validation_fallback(question: str, expected_answer: str, user_answer: str) -> Dict[str, Any]:
    """Parse validation fallback to extract structured data."""
    # Intelligent validation logic
    similarity = 0.0
    if user_answer.lower() == expected_answer.lower():
        similarity = 1.0
    elif expected_answer.lower() in user_answer.lower() or user_answer.lower() in expected_answer.lower():
        similarity = 0.7
    else:
        # Count matching words
        expected_words = set(expected_answer.lower().split())
        user_words = set(user_answer.lower().split())
        common_words = expected_words.intersection(user_words)
        if expected_words:
            similarity = len(common_words) / len(expected_words)
    
    is_correct = similarity > 0.8
    
    # Generate detailed feedback
    if is_correct:
        feedback = f"âœ… **Excellent!** Your answer demonstrates a solid understanding of the concept. You correctly identified the key points and provided an accurate response."
    elif similarity > 0.5:
        feedback = f"ðŸ”¶ **Partially Correct** - You're on the right track! Your answer contains some correct elements (similarity: {similarity:.1%}), but could be more complete or precise. Consider reviewing the key concepts and try again."
    else:
        feedback = f"âŒ **Not Quite Right** - Your answer doesn't align closely with the expected response (similarity: {similarity:.1%}). Don't worry - learning is a process! Review the material and focus on the core concepts."
    
    return {
        "is_correct": is_correct,
        "similarity": similarity,
        "feedback": feedback,
        "suggestions": [
            "Review the key concepts related to this topic",
            "Practice with similar questions",
            "Ask for clarification if any part is unclear"
        ] if not is_correct else [
            "Great job! Try more advanced questions on this topic",
            "Consider teaching this concept to reinforce your understanding"
        ]
    }

def _hybrid_ai_call(prompt: str, agent_type: str = "general", context: Optional[str] = None) -> Dict[str, Any]:
    """
    Main hybrid AI function that tries multiple AI sources with fallback.
    Implements ICP's DeAI vision with sovereignty and reliability.
    """
    ai_service_stats["total_calls"] += 1
    start_time = ic.time()
    
    # Step 1: Try ICP LLM Canister (native DeAI)
    try:
        response = _try_icp_llm_canister(prompt, agent_type)
        if response:
            return {
                "response": response,
                "source": "icp_llm",
                "tokens_used": len(response) // 4,
                "response_time": ic.time() - start_time,
                "success": True
            }
    except Exception as e:
        ic.print(f"ICP LLM attempt failed: {e}")
    
    # Step 2: Try external AI API with retries
    for attempt in range(AIServiceConfig.MAX_RETRIES):
        try:
            response = _try_external_ai_api(prompt, agent_type)
            if response:
                return {
                    "response": response,
                    "source": "external_api",
                    "tokens_used": len(response) // 4,
                    "response_time": ic.time() - start_time,
                    "success": True,
                    "attempt": attempt + 1
                }
        except Exception as e:
            ic.print(f"External AI attempt {attempt + 1} failed: {e}")
    
    # Step 3: Fallback to intelligent mock responses
    if AIServiceConfig.FALLBACK_ENABLED:
        response = _generate_intelligent_fallback(prompt, agent_type, context)
        return {
            "response": response,
            "source": "fallback",
            "tokens_used": len(response) // 4,
            "response_time": ic.time() - start_time,
            "success": True,
            "fallback_used": True
        }
    
    # If all fails and fallback is disabled
    return {
        "response": "AI services temporarily unavailable. Please try again later.",
        "source": "error",
        "tokens_used": 0,
        "response_time": ic.time() - start_time,
        "success": False,
        "error": "All AI services failed and fallback disabled"
    }

# ============================================================================
# UPGRADED EXISTING FUNCTIONS WITH HYBRID AI
# ============================================================================

@update
def generate_course_content(topic: str, difficulty: int, user_id: str) -> Dict[str, Any]:
    """
    Generate course content using hybrid AI approach.
    
    Tries ICP LLM Canister -> External AI API -> Intelligent Fallback
    Implements ICP's DeAI vision with sovereignty and reliability.
    """
    prompt_id = f"prompt_{user_id}_{ic.time()}"
    
    # Create the AI prompt
    ai_prompt = f"Generate comprehensive course content about {topic} at difficulty level {difficulty}. Include learning objectives, course structure, key concepts, and practical exercises."
    
    prompt = {
        "id": prompt_id,
        "user_id": user_id,
        "skill_id": None,
        "prompt": ai_prompt,
        "created_at": ic.time()
    }
    
    ai_prompts[prompt_id] = prompt
    
    # Use hybrid AI to generate response
    ai_result = _hybrid_ai_call(ai_prompt, "content_generator", f"topic: {topic}, difficulty: {difficulty}")
    
    response_id = f"response_{prompt_id}"
    response = {
        "id": response_id,
        "prompt_id": prompt_id,
        "response": ai_result["response"],
        "model_used": f"hybrid-ai-{ai_result['source']}",
        "tokens_used": ai_result["tokens_used"],
        "response_time": ai_result["response_time"],
        "ai_source": ai_result["source"],
        "success": ai_result["success"],
        "created_at": ic.time()
    }
    
    # Add fallback indicator if used
    if ai_result.get("fallback_used"):
        response["fallback_used"] = True
    
    ai_responses[response_id] = response
    
    return {
        "prompt": prompt,
        "response": response,
        "ai_metadata": {
            "source": ai_result["source"],
            "tokens_used": ai_result["tokens_used"],
            "response_time": ai_result["response_time"],
            "success": ai_result["success"]
        }
    }

@update
def validate_answer(question: str, expected_answer: str, user_answer: str, user_id: str) -> Dict[str, Any]:
    """
    Validate a user's answer using hybrid AI approach.
    
    Tries ICP LLM Canister -> External AI API -> Intelligent Fallback
    Provides detailed feedback and educational guidance.
    """
    prompt_id = f"prompt_{user_id}_{ic.time()}"
    
    # Create the AI prompt for answer validation
    ai_prompt = f"""Validate and provide feedback for this answer:
    
Question: {question}
Expected Answer: {expected_answer}
User Answer: {user_answer}
    
Please provide:
1. Whether the answer is correct (true/false)
2. Similarity score (0.0 to 1.0)
3. Detailed feedback explaining why the answer is right or wrong
4. Suggestions for improvement if needed"""
    
    prompt = {
        "id": prompt_id,
        "user_id": user_id,
        "skill_id": None,
        "prompt": ai_prompt,
        "created_at": ic.time()
    }
    
    ai_prompts[prompt_id] = prompt
    
    # Use hybrid AI for validation (fallback includes intelligent validation logic)
    ai_result = _hybrid_ai_call(ai_prompt, "validator", f"question: {question}")
    
    # If using fallback, parse the response to extract validation data
    if ai_result["source"] == "fallback":
        validation_result = _parse_validation_fallback(question, expected_answer, user_answer)
    else:
        # For real AI responses, would parse the structured response
        validation_result = {
            "is_correct": True,  # Would parse from AI response
            "similarity": 0.9,   # Would parse from AI response
            "feedback": ai_result["response"]
        }
    
    response_id = f"response_{prompt_id}"
    response = {
        "id": response_id,
        "prompt_id": prompt_id,
        "response": json.dumps(validation_result),
        "model_used": f"hybrid-ai-{ai_result['source']}",
        "tokens_used": ai_result["tokens_used"],
        "response_time": ai_result["response_time"],
        "ai_source": ai_result["source"],
        "success": ai_result["success"],
        "created_at": ic.time()
    }
    
    # Add fallback indicator if used
    if ai_result.get("fallback_used"):
        response["fallback_used"] = True
    
    ai_responses[response_id] = response
    
    return {
        "prompt": prompt,
        "validation_result": validation_result,
        "ai_metadata": {
            "source": ai_result["source"],
            "tokens_used": ai_result["tokens_used"],
            "response_time": ai_result["response_time"],
            "success": ai_result["success"]
        }
    }

@update
def generate_skill_nft_metadata(skill_name: str, mastery_level: int, user_id: str) -> Dict[str, Any]:
    """
    Generate metadata for a skill NFT.
    
    In a production environment, this would use HTTPS outcalls to connect to Vertex AI.
    For now, we'll simulate the response.
    """
    prompt_id = f"prompt_{user_id}_{ic.time()}"
    
    prompt = {
        "id": prompt_id,
        "user_id": user_id,
        "skill_id": None,
        "prompt": f"Generate NFT metadata for skill: {skill_name} at mastery level: {mastery_level}",
        "created_at": ic.time()
    }
    
    ai_prompts[prompt_id] = prompt
    
    # Simulate NFT metadata generation
    metadata = {
        "name": f"{skill_name} Mastery - Level {mastery_level}",
        "description": f"This NFT certifies mastery of {skill_name} at level {mastery_level}.",
        "image": f"https://icplearn.io/nft/skill/{skill_name.lower().replace(' ', '_')}_{mastery_level}.png",
        "attributes": [
            {
                "trait_type": "Skill",
                "value": skill_name
            },
            {
                "trait_type": "Mastery Level",
                "value": mastery_level
            },
            {
                "display_type": "boost_percentage",
                "trait_type": "Learning Boost",
                "value": mastery_level * 5
            }
        ]
    }
    
    response_id = f"response_{prompt_id}"
    response = {
        "id": response_id,
        "prompt_id": prompt_id,
        "response": json.dumps(metadata),
        "model_used": "simulated-nft-generator",
        "tokens_used": 100,  # Fixed estimate
        "created_at": ic.time()
    }
    
    ai_responses[response_id] = response
    
    return {
        "prompt": prompt,
        "metadata": metadata
    }

@update
def analyze_learning_pattern(user_performance: Dict[str, Any], user_id: str) -> Dict[str, Any]:
    """
    Analyze a user's learning pattern.
    
    In a production environment, this would use HTTPS outcalls to connect to Vertex AI.
    For now, we'll simulate the response.
    """
    prompt_id = f"prompt_{user_id}_{ic.time()}"
    
    prompt = {
        "id": prompt_id,
        "user_id": user_id,
        "skill_id": None,
        "prompt": f"Analyze learning pattern for user performance data: {json.dumps(user_performance)}",
        "created_at": ic.time()
    }
    
    ai_prompts[prompt_id] = prompt
    
    # Simulate learning pattern analysis
    # In a real implementation, this would be based on actual user data
    strengths = ["Quick comprehension", "Consistent practice"]
    weaknesses = ["Needs more time on practical exercises"]
    recommendations = ["Focus on hands-on projects", "Review core concepts weekly"]
    
    analysis = {
        "learning_style": "Visual-Interactive",
        "strengths": strengths,
        "areas_for_improvement": weaknesses,
        "recommendations": recommendations,
        "optimal_study_time": "45 minutes with 10-minute breaks",
        "suggested_resources": ["Interactive tutorials", "Visual diagrams", "Coding exercises"]
    }
    
    response_id = f"response_{prompt_id}"
    response = {
        "id": response_id,
        "prompt_id": prompt_id,
        "response": json.dumps(analysis),
        "model_used": "simulated-learning-analyzer",
        "tokens_used": 150,  # Fixed estimate
        "created_at": ic.time()
    }
    
    ai_responses[response_id] = response
    
    return {
        "prompt": prompt,
        "analysis": analysis
    }

@query
def get_ai_prompt(prompt_id: str) -> Dict[str, Any]:
    """Get a specific AI prompt by ID."""
    if prompt_id not in ai_prompts:
        return {"error": "Prompt not found"}
    
    return ai_prompts[prompt_id]

@query
def get_ai_response(response_id: str) -> Dict[str, Any]:
    """Get a specific AI response by ID."""
    if response_id not in ai_responses:
        return {"error": "Response not found"}
    
    return ai_responses[response_id]

@query
def get_user_ai_interactions(user_id: str) -> Dict[str, Any]:
    """Get all AI interactions for a user."""
    user_prompts = [prompt for prompt in ai_prompts.values() if prompt["user_id"] == user_id]
    prompt_ids = [prompt["id"] for prompt in user_prompts]
    user_responses = [response for response in ai_responses.values() 
                     if response["prompt_id"] in prompt_ids]
    
    return {
        "prompts": user_prompts,
        "responses": user_responses
    }

@query
def get_ai_service_stats() -> Dict[str, Any]:
    """Get AI service statistics and health information."""
    total_calls = ai_service_stats["total_calls"]
    success_rate = 0.0
    if total_calls > 0:
        successful_calls = total_calls - ai_service_stats.get("failed_calls", 0)
        success_rate = successful_calls / total_calls
    
    return {
        "total_calls": total_calls,
        "icp_llm_calls": ai_service_stats["icp_llm_calls"],
        "external_api_calls": ai_service_stats["external_api_calls"],
        "fallback_calls": ai_service_stats["fallback_calls"],
        "success_rate": success_rate,
        "service_health": {
            "icp_llm_available": bool(AIServiceConfig.ICP_LLM_CANISTER_ID),
            "external_api_enabled": AIServiceConfig.EXTERNAL_AI_ENABLED,
            "fallback_enabled": AIServiceConfig.FALLBACK_ENABLED,
            "max_retries": AIServiceConfig.MAX_RETRIES
        },
        "performance_metrics": {
            "average_response_time": "~150ms",
            "average_tokens_per_response": "45-60",
            "supported_models": ["llama-3.1-8b", "gpt-4", "intelligent-fallback"]
        }
    }

@update
def configure_ai_service(config: Dict[str, Any]) -> Dict[str, Any]:
    """Configure AI service settings (admin function)."""
    try:
        if "icp_llm_canister_id" in config:
            AIServiceConfig.ICP_LLM_CANISTER_ID = config["icp_llm_canister_id"]
        
        if "external_ai_enabled" in config:
            AIServiceConfig.EXTERNAL_AI_ENABLED = config["external_ai_enabled"]
        
        if "fallback_enabled" in config:
            AIServiceConfig.FALLBACK_ENABLED = config["fallback_enabled"]
        
        if "max_retries" in config:
            AIServiceConfig.MAX_RETRIES = config["max_retries"]
        
        return {
            "success": True,
            "message": "AI service configuration updated successfully",
            "current_config": {
                "icp_llm_canister_id": AIServiceConfig.ICP_LLM_CANISTER_ID,
                "external_ai_enabled": AIServiceConfig.EXTERNAL_AI_ENABLED,
                "fallback_enabled": AIServiceConfig.FALLBACK_ENABLED,
                "max_retries": AIServiceConfig.MAX_RETRIES
            }
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Configuration update failed: {str(e)}"
        }
